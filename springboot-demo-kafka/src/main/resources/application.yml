spring:
  kafka:
    # kafka集群信息
    bootstrap-servers: 10.1.1.68:19092,10.1.1.68:29092,10.1.1.68:39092
    # 生产者配置
    producer:
      # 开启事务，必须在开启了事务的方法中发送，否则报错
      transaction-id-prefix: kafka-tx-
      # 设置大于0的值，则客户端会将发送失败的记录重新发送,开启事务必须设置大于0,默认值整形最大数
      retries: 3
      # 当有多个消息需要被发送到同一个分区时，生产者会把它们放在同一个批次里。该参数指定了一个批次可以使用的内存大小，按照字节数计算。16M
      batch-size: 16384
      # 设置生产者内存缓冲区的大小。#32M
      buffer-memory: 33554432
      # acks: 0 ： 生产者在成功写入消息之前不会等待任何来自服务器的响应。
      # acks: 1 ： 只要集群的首领节点收到消息，生产者就会收到一个来自服务器成功响应。
      # acks: -1/all ：只有当所有参与复制的节点全部收到消息时，生产者才会收到一个来自服务器的成功响应。
      acks: all
      # 指定消息key和消息体的编解码方式 值的序列化方式
      key-serializer: org.apache.kafka.common.serialization.StringSerializer
      # 值的序列化方式 (建议使用Json，这种序列化方式可以无需额外配置传输实体类)
      value-serializer: org.springframework.kafka.support.serializer.JsonSerializer
      properties:
        # 生产者客户端会在 ProducerBatch 被填满或等待时间超过 linger.ms 值时发送出去, 默认是0，建议1到100ms最佳
        linger.ms: 50
        # 压缩类型	压缩率	    CPU使用率  压缩速度	带宽使用率
        # gzip	    Highest	    Highest	  Slowest	Lowest
        # snappy	Medium	    Moderate  Moderate	Medium
        # lz4	    Low      	Lowest 	  Fastest   Highest
        # zstd	    Medium	    Moderate  Moderate	Medium
        # 压缩必定带来消息延迟，如果对延迟很有要求的则不建议压缩
        compression.type: lz4
        # 是否开启幂等，开启幂等后 acks 默认为all/-1如果设置为0或1则直接启动报错
        enable.idempotence: true
        # 重试间隔 经验值：20000。默认值：1000,设置此项，使其过段时间后再重试，这时网络可能已经好了。重试若间隔太近，短时间网络还没好，会浪费了重试次数
        retry.backoff.ms: 20000
        # 该参数表示Kafka客户端重连的最大时间，每次连接失败，重连时间都会成指数级增加，每次增加的时间会在20%随机浮动，以避免连接风暴出现
        # reconnect.backoff.max.ms
        # 客户端重连kafka间隔,经验值：20000。默认值：50
        reconnect.backoff.ms: 20000
    # 消费者配置
    consumer:
      # 消费者组名称
      group-id: boot-2
      # 这个参数定义了poll方法最多可以拉取多少条消息，默认值为500。如果在拉取消息的时候新消息不足500条，那有多少返回多少；如果超过500条，每次只返回500。
      # 这个默认值在有些场景下太大，有些场景很难保证能够在5min内处理完500条消息，
      # 如果消费者无法在5分钟内处理完500条消息的话就会触发reBalance,
      # 然后这批消息会被分配到另一个消费者中，还是会处理不完，这样这批消息就永远也处理不完。
      # 要避免出现上述问题，提前评估好处理一条消息最长需要多少时间，然后覆盖默认的max.poll.records参数
      # 注：需要开启BatchListener批量监听才会生效，如果不开启BatchListener则不会出现reBalance情况
      max-poll-records: 3
      # 该属性指定了消费者在读取一个没有偏移量的分区或者偏移量无效的情况下该作何处理：
      # earliest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，从头开始消费分区的记录
      # latest：当各分区下有已提交的offset时，从提交的offset开始消费；无提交的offset时，消费新产生的该分区下的数据（在消费者启动之后生成的记录）
      # none：当各分区都存在已提交的offset时，从提交的offset开始消费；只要有一个分区不存在已提交的offset，则抛出异常
      auto-offset-reset: earliest
      # 自动提交的时间间隔  刷新间隔时间，负值失败时候刷新，0每次发送后刷新
      # 自动提交的时间间隔 在spring boot 2.X 版本中这里采用的是值的类型为Duration 需要符合特定的格式，如1S,1M,2H,5D
      # auto-commit-interval: 1s
      # 是否自动提交偏移量，默认值是true,为了避免出现重复数据和数据丢失，可以把它设置为false,然后手动提交偏移量
      # 建议手动提交
      enable-auto-commit: false
      # 键的反序列化方式
      key-deserializer: org.apache.kafka.common.serialization.StringDeserializer
      # 值的反序列化方式 (建议使用Json，这种序列化方式可以无需额外配置传输实体类)
      value-deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
      properties:
        # 两次poll之间的最大间隔，默认值为5分钟。如果超过这个间隔会触发reBalance
        max.poll.interval.ms: 600000
        # 消费会话超时时间（超过这个时间 consumer 没有发送心跳，就会触发 rebalance 操作）
        session.timeout.ms: 10000
        # 消费请求的超时时间
        request.timeout.ms: 18000
        # 配置消费者的 Json 反序列化的可信赖包，反序列化实体类需要 官网文档:https://docs.spring.io/spring-kafka/reference/kafka/serdes.html#json-serde
        spring.json.trusted.packages: "*"
    listener:
      # 设置批量消费,默认single
      type: batch
      # 在侦听器容器中运行的线程数，一般设置为 机器数*分区数
      concurrency: 4
      # 自动提交关闭，需要设置手动消息确认
      ack-mode: manual_immediate
      # 消费监听接口监听的主题不存在时，默认会报错，所以设置为false忽略错误
      missing-topics-fatal: false
      # 两次poll之间的最大间隔，默认值为5分钟。如果超过这个间隔会触发reBalance
      poll-timeout: 600000

